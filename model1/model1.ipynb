import numpy as np
import matplotlib.pyplot as plt

train_inp = np.loadtxt('train_input.csv', delimiter=',')
train_out = np.loadtxt('train_output.csv', delimiter=',')
test_inp = np.loadtxt('test_input.csv', delimiter=',')
test_out = np.loadtxt('test_output.csv', delimiter=',')

alpha = 0.002
iters = 3000
theta = np.array([1.0, 1.0])

def computeCost(X, y, theta,pow): #if pow = 1 then mean absolute error
    sum=0
    for i in range(len(X)):
        sum+=abs(np.power(X[i]*theta[0] + theta[1] - y[i],pow))
    return sum/(pow*len(X))

def gradientDescentmae(X, y, theta, alpha, iters):
    prevcost = 1e21
    for i in range(iters):
        temp=0
        a=0
        for j in range(len(X)):
            if(X[j]*theta[0] + theta[1] > y[j]):
                temp+=X[j]
                a+=1
            else:
                temp-=X[j]
                a-=1
        theta[0] = theta[0] - (alpha/len(X))*temp*theta[0]
        theta[1] = theta[1] - (alpha/len(X))*a*theta[1]
        cost = computeCost(X, y, theta,1)
        if(cost>prevcost):
            break
        prevcost = cost
        # if i % 100 == 0:
        #     print(cost)
    return (theta, cost)


(op_theta, op_cost) = gradientDescentmae(train_inp, train_out,theta,alpha,iters)

print(op_theta)

preds = []
for i in range(len(test_inp)):
    preds.append(op_theta[0]*test_inp[i] + op_theta[1])

plt.plot(test_inp,preds,'*')
plt.plot(test_inp,test_out,'.')
plt.show()
plt.savefig('../model1/model1_final.jpg')
np.savetxt('../model1/res1.csv', op_theta, delimiter=',')
